{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6kZCfTT47ei"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/MF_India_AI.csv\")"
      ],
      "metadata": {
        "id": "pTk5JpnJes8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "ovSHuC_bfLqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "puYthM-ZfOZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "bBSQczGifOhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "LlndpgVpfOkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "id": "jAQg10kMfOnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['amc_name'])['returns_5yr'].mean()"
      ],
      "metadata": {
        "id": "2NPxrlqZVDnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= data.groupby(['amc_name'])['returns_5yr'].mean().nlargest()\n",
        "b= data.groupby(['category'])['returns_5yr'].mean()"
      ],
      "metadata": {
        "id": "yO_YNaS8VDtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "JW_lyPoKVDvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "GWuOXKvBXLBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=a.values, y=a.index, palette='viridis')\n",
        "plt.title('Mean Returns (5yr) by amc_name (Top Largest)')\n",
        "plt.xlabel('Mean Returns (5yr)')\n",
        "plt.ylabel('AMC Name')\n",
        "plt.show()\n",
        "\n",
        "# Plotting for 'b'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=b.values, y=b.index, palette='viridis')\n",
        "plt.title('Mean Returns (5yr) by Category')\n",
        "plt.xlabel('Mean Returns (5yr)')\n",
        "plt.ylabel('Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CMsD6wxPVDyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c= data.groupby(['sub_category'])['returns_5yr'].mean()"
      ],
      "metadata": {
        "id": "iyczRaCIVD1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "id": "NSDjxQXcVD4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=c.values, y=c.index, palette='viridis')\n",
        "plt.title('Mean Returns (5yr) by sub_Category')\n",
        "plt.xlabel('Mean Returns (5yr)')\n",
        "plt.ylabel('sub_Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yzJCcolzVD7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph for rattings\n",
        "d= data.groupby(['rating'])['returns_5yr'].count().nlargest()\n",
        "d"
      ],
      "metadata": {
        "id": "sk67tOnNVD_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=d.values, y=d.index, palette='viridis')\n",
        "plt.title('Mean Returns (5yr) by ratings')\n",
        "plt.xlabel('Mean Returns (5yr)')\n",
        "plt.ylabel('sub_Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yFqH9N6FVECv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle dropdown selection\n",
        "def plot_graph(column, sub_column=None):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.clf()  # Clear current figure\n",
        "    if sub_column is None:\n",
        "        data[column].value_counts().plot(kind='bar')\n",
        "        plt.title(f'Bar Graph of {column}')\n",
        "        plt.xlabel(column)\n",
        "    else:\n",
        "        filtered_data = data[data['category'] == sub_column]\n",
        "        if not filtered_data.empty:\n",
        "            filtered_data[column].value_counts().plot(kind='bar')\n",
        "            plt.title(f'Bar Graph of {column} for {sub_column}')\n",
        "            plt.xlabel(column + ' (' + sub_column + ')')\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'No data available for selected sub-category', horizontalalignment='center', verticalalignment='center')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Dropdown widget for main column selection\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=data.columns,\n",
        "    description='Select Column:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Dropdown widget for sub-category selection\n",
        "sub_dropdown = widgets.Dropdown(\n",
        "    description='Select Sub-Category:',\n",
        "    disabled=True,\n",
        ")\n",
        "\n",
        "# Button widget to trigger plot\n",
        "search_button = widgets.Button(\n",
        "    description='Search',\n",
        "    disabled=False,\n",
        "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to plot graph',\n",
        "    icon='search'  # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle button click event\n",
        "def on_button_click(b):\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        plot_graph(dropdown.value, sub_dropdown.value if not sub_dropdown.disabled else None)\n",
        "\n",
        "# Event handler for main dropdown selection\n",
        "def on_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        if change['new'] in ['category', 'sub_category']:\n",
        "            sub_dropdown.options = sorted(data[change['new']].unique())\n",
        "            sub_dropdown.disabled = False\n",
        "        else:\n",
        "            sub_dropdown.disabled = True\n",
        "            sub_dropdown.value = None\n",
        "        output.clear_output()\n",
        "        with output:\n",
        "            plot_graph(change['new'])\n",
        "\n",
        "# Event handler for sub-dropdown selection\n",
        "def on_sub_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        output.clear_output()\n",
        "        with output:\n",
        "            plot_graph(dropdown.value, change['new'])\n",
        "\n",
        "# Registering event handlers\n",
        "dropdown.observe(on_change)\n",
        "sub_dropdown.observe(on_sub_change)\n",
        "search_button.on_click(on_button_click)\n",
        "\n",
        "# Displaying widgets\n",
        "display(dropdown)\n",
        "display(sub_dropdown)\n",
        "display(search_button)\n",
        "display(output)"
      ],
      "metadata": {
        "id": "zfCK3Nq_e94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rj9CcFmPVuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define the label encoder\n",
        "encoder = LabelEncoder()\n",
        "data['category'] = leobject.fit_transform(data['category'])\n",
        "data['sub_category']= leobject.fit_transform(data['sub_category'])\n",
        "data['scheme_name'] = leobject.fit_transform(data['scheme_name'])\n",
        "data['amc_name'] =  leobject.fit_transform(data['amc_name'])\n",
        "data['fund_manager'] = leobject.fit_transform(data['fund_manager'])\n",
        "data['sortino'] = pd.to_numeric(data['sortino'], errors='coerce')\n",
        "data['sortino'] = data['sortino'].fillna(data['sortino'].mean())\n",
        "data['alpha'] = pd.to_numeric(data['alpha'], errors='coerce')\n",
        "data['alpha'] = data['alpha'].fillna(data['alpha'].mean())\n",
        "data['sd'] = pd.to_numeric(data['sd'], errors='coerce')\n",
        "data['sd'] = data['sd'].fillna(data['sd'].mean())\n",
        "data['beta'] = pd.to_numeric(data['beta'], errors='coerce')\n",
        "data['beta'] = data['beta'].fillna(data['beta'].mean())\n",
        "data['sharpe'] = pd.to_numeric(data['sharpe'], errors='coerce')\n",
        "data['sharpe'] = data['sharpe'].fillna(data['sharpe'].mean())\n",
        "data['risk_level'] = pd.to_numeric(data['risk_level'], errors='coerce')\n",
        "data['amc_name'] = pd.to_numeric(data['amc_name'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "OZfJwNAuhY9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "fPZFViQfexuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l_Bz-wJjKZI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "metadata": {
        "id": "Yl7aoLsKfOsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "RtGFTIPoIo5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "FoiQcwnofOu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uxwjtp1W2KX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data['returns_3yr'].isnull().any() or data['returns_5yr'].isnull().any():\n",
        "    data1 = data.dropna(subset=['returns_3yr'])\n",
        "    data1 = data.dropna(subset=['returns_5yr'])\n",
        "else :\n",
        "  data1 = data"
      ],
      "metadata": {
        "id": "yWrnqF-zfOyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.head(15)"
      ],
      "metadata": {
        "id": "J4SN8yj2t6qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "\n",
        "if data['returns_3yr'].isnull().any() or data['returns_5yr'].isnull().any():\n",
        "    data1 = data.dropna(subset=['returns_3yr', 'returns_5yr'])\n",
        "else:\n",
        "    data1 = data\n",
        "\n",
        "# For the 1st return\n",
        "X = data1.drop(columns=['returns_1yr'])\n",
        "y = data1['returns_1yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "random_forest = RandomForestRegressor(random_state=42)\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "mse_1 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (1st return):\", mse_1)\n",
        "\n",
        "mae_1 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (1st return):\", mae_1)\n",
        "\n",
        "r_squared_1 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (1st return):\", r_squared_1)\n",
        "\n",
        "\n",
        "# For the 3rd return\n",
        "X = data1.drop(columns=['returns_3yr'])\n",
        "y = data1['returns_3yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "random_forest = RandomForestRegressor(random_state=42)\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "mse_3 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (3rd return):\", mse_3)\n",
        "\n",
        "mae_3 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (3rd return):\", mae_3)\n",
        "\n",
        "r_squared_3 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (3rd return):\", r_squared_3)\n",
        "\n",
        "\n",
        "# For the 5th return\n",
        "X = data1.drop(columns=['returns_5yr'])\n",
        "y = data1['returns_5yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "random_forest = RandomForestRegressor(random_state=42)\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "mse_5 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (5th return):\", mse_5)\n",
        "\n",
        "mae_5 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (5th return):\", mae_5)\n",
        "\n",
        "r_squared_5 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (5th return):\", r_squared_5)\n"
      ],
      "metadata": {
        "id": "bkK6T4lLUz4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "\n",
        "if data['returns_3yr'].isnull().any() or data['returns_5yr'].isnull().any():\n",
        "    data1 = data.dropna(subset=['returns_3yr', 'returns_5yr'])\n",
        "else:\n",
        "    data1 = data\n",
        "\n",
        "# For the 1st return\n",
        "X = data1.drop(columns=['returns_1yr'])\n",
        "y = data1['returns_1yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "mse_1 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (1st return):\", mse_1)\n",
        "\n",
        "mae_1 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (1st return):\", mae_1)\n",
        "\n",
        "r_squared_1 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (1st return):\", r_squared_1)\n",
        "\n",
        "\n",
        "# For the 3rd return\n",
        "X = data1.drop(columns=['returns_3yr'])\n",
        "y = data1['returns_3yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "mse_3 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (3rd return):\", mse_3)\n",
        "\n",
        "mae_3 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (3rd return):\", mae_3)\n",
        "\n",
        "r_squared_3 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (3rd return):\", r_squared_3)\n",
        "\n",
        "\n",
        "# For the 5th return\n",
        "X = data1.drop(columns=['returns_5yr'])\n",
        "y = data1['returns_5yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "mse_5 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (5th return):\", mse_5)\n",
        "\n",
        "mae_5 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (5th return):\", mae_5)\n",
        "\n",
        "r_squared_5 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (5th return):\", r_squared_5)\n"
      ],
      "metadata": {
        "id": "2orju11qTkSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "\n",
        "if data['returns_3yr'].isnull().any() or data['returns_5yr'].isnull().any():\n",
        "    data1 = data.dropna(subset=['returns_3yr', 'returns_5yr'])\n",
        "else:\n",
        "    data1 = data\n",
        "\n",
        "# For the 1st return\n",
        "X = data1.drop(columns=['returns_1yr'])\n",
        "y = data1['returns_1yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "mse_1 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (1st return):\", mse_1)\n",
        "\n",
        "mae_1 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (1st return):\", mae_1)\n",
        "\n",
        "r_squared_1 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (1st return):\", r_squared_1)\n",
        "\n",
        "\n",
        "# For the 3rd return\n",
        "X = data1.drop(columns=['returns_3yr'])\n",
        "y = data1['returns_3yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "mse_3 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (3rd return):\", mse_3)\n",
        "\n",
        "mae_3 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (3rd return):\", mae_3)\n",
        "\n",
        "r_squared_3 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (3rd return):\", r_squared_3)\n",
        "\n",
        "\n",
        "# For the 5th return\n",
        "X = data1.drop(columns=['returns_5yr'])\n",
        "y = data1['returns_5yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "mse_5 = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (5th return):\", mse_5)\n",
        "\n",
        "mae_5 = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (5th return):\", mae_5)\n",
        "\n",
        "r_squared_5 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (5th return):\", r_squared_5)\n"
      ],
      "metadata": {
        "id": "uwtKjzznVAw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# For the 1st return\n",
        "X = data1.drop(columns=['returns_1yr'])\n",
        "y = data1['returns_1yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "random_forest = RandomForestRegressor(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "mse_rf_1 = mean_squared_error(y_test, y_pred_rf)\n",
        "mae_rf_1 = mean_absolute_error(y_test, y_pred_rf)\n",
        "r_squared_rf_1 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Linear Regression\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred_lr = linear_reg.predict(X_test)\n",
        "mse_lr_1 = mean_squared_error(y_test, y_pred_lr)\n",
        "mae_lr_1 = mean_absolute_error(y_test, y_pred_lr)\n",
        "r_squared_lr_1 = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "# Decision Tree\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "mse_dt_1 = mean_squared_error(y_test, y_pred_dt)\n",
        "mae_dt_1 = mean_absolute_error(y_test, y_pred_dt)\n",
        "r_squared_dt_1 = r2_score(y_test, y_pred_dt)\n",
        "\n",
        "results.append({'Return Period': '1st',\n",
        "                'MSE (Random Forest)': mse_rf_1, 'MAE (Random Forest)': mae_rf_1, 'R-squared (Random Forest)': r_squared_rf_1,\n",
        "                'MSE (Linear Regression)': mse_lr_1, 'MAE (Linear Regression)': mae_lr_1, 'R-squared (Linear Regression)': r_squared_lr_1,\n",
        "                'MSE (Decision Tree)': mse_dt_1, 'MAE (Decision Tree)': mae_dt_1, 'R-squared (Decision Tree)': r_squared_dt_1})\n",
        "\n",
        "# For the 3rd return\n",
        "X = data1.drop(columns=['returns_3yr'])\n",
        "y = data1['returns_3yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "mse_rf_3 = mean_squared_error(y_test, y_pred_rf)\n",
        "mae_rf_3 = mean_absolute_error(y_test, y_pred_rf)\n",
        "r_squared_rf_3 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Linear Regression\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred_lr = linear_reg.predict(X_test)\n",
        "mse_lr_3 = mean_squared_error(y_test, y_pred_lr)\n",
        "mae_lr_3 = mean_absolute_error(y_test, y_pred_lr)\n",
        "r_squared_lr_3 = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "# Decision Tree\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "mse_dt_3 = mean_squared_error(y_test, y_pred_dt)\n",
        "mae_dt_3 = mean_absolute_error(y_test, y_pred_dt)\n",
        "r_squared_dt_3 = r2_score(y_test, y_pred_dt)\n",
        "\n",
        "results.append({'Return Period': '3rd',\n",
        "                'MSE (Random Forest)': mse_rf_3, 'MAE (Random Forest)': mae_rf_3, 'R-squared (Random Forest)': r_squared_rf_3,\n",
        "                'MSE (Linear Regression)': mse_lr_3, 'MAE (Linear Regression)': mae_lr_3, 'R-squared (Linear Regression)': r_squared_lr_3,\n",
        "                'MSE (Decision Tree)': mse_dt_3, 'MAE (Decision Tree)': mae_dt_3, 'R-squared (Decision Tree)': r_squared_dt_3})\n",
        "\n",
        "# For the 5th return\n",
        "X = data1.drop(columns=['returns_5yr'])\n",
        "y = data1['returns_5yr']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "mse_rf_5 = mean_squared_error(y_test, y_pred_rf)\n",
        "mae_rf_5 = mean_absolute_error(y_test, y_pred_rf)\n",
        "r_squared_rf_5 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Linear Regression\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred_lr = linear_reg.predict(X_test)\n",
        "mse_lr_5 = mean_squared_error(y_test, y_pred_lr)\n",
        "mae_lr_5 = mean_absolute_error(y_test, y_pred_lr)\n",
        "r_squared_lr_5 = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "# Decision Tree\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "mse_dt_5 = mean_squared_error(y_test, y_pred_dt)\n",
        "mae_dt_5 = mean_absolute_error(y_test, y_pred_dt)\n",
        "r_squared_dt_5 = r2_score(y_test, y_pred_dt)\n",
        "\n",
        "results.append({'Return Period': '5th',\n",
        "                'MSE (Random Forest)': mse_rf_5, 'MAE (Random Forest)': mae_rf_5, 'R-squared (Random Forest)': r_squared_rf_5,\n",
        "                'MSE (Linear Regression)': mse_lr_5, 'MAE (Linear Regression)': mae_lr_5, 'R-squared (Linear Regression)': r_squared_lr_5,\n",
        "                'MSE (Decision Tree)': mse_dt_5, 'MAE (Decision Tree)': mae_dt_5, 'R-squared (Decision Tree)': r_squared_dt_5})\n",
        "\n",
        "# Create DataFrame and print results\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ],
      "metadata": {
        "id": "TKROUJhRVEHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_metrics = df_results.mean()\n",
        "\n",
        "# Find the model with the lowest average MSE and MAE and the highest average R-squared value\n",
        "best_model_mse_mae = avg_metrics[['MSE (Random Forest)', 'MAE (Random Forest)',\n",
        "                                  'MSE (Linear Regression)', 'MAE (Linear Regression)',\n",
        "                                  'MSE (Decision Tree)', 'MAE (Decision Tree)']].idxmin()\n",
        "\n",
        "best_model_r_squared = avg_metrics[['R-squared (Random Forest)', 'R-squared (Linear Regression)',\n",
        "                                    'R-squared (Decision Tree)']].idxmax()\n",
        "\n",
        "print(\"Best model based on MSE and MAE:\", best_model_mse_mae)\n",
        "print(\"Best model based on R-squared:\", best_model_r_squared)"
      ],
      "metadata": {
        "id": "VjVb6YoHVPAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RECOMMENDATION ON THE BASIS OF RETURNS AND CATEGORIES"
      ],
      "metadata": {
        "id": "3Xevljxq54Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(), inplace=True)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "h_zPNHIpSHzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Sample data loading (replace with your actual data)\n",
        "data = pd.read_csv('/content/MF_India_AI.csv')\n",
        "\n",
        "# Impute missing values with the mean\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# Data Preprocessing\n",
        "encoder = LabelEncoder()\n",
        "data['category_encoded'] = encoder.fit_transform(data['category'])  # Encode category\n",
        "scaler = StandardScaler()\n",
        "data[['risk_level', 'returns_1yr', 'returns_3yr', 'returns_5yr']] = scaler.fit_transform(data[['risk_level', 'returns_1yr', 'returns_3yr', 'returns_5yr']])  # Normalize numerical columns\n",
        "\n",
        "# Calculate Cosine Similarity\n",
        "def calculate_similarity(target, data):\n",
        "    similarity_scores = cosine_similarity(target, data)\n",
        "    return similarity_scores\n",
        "\n",
        "# Recommend Similar Schemes based on user input\n",
        "def recommend_similar_schemes(user_input, data, top_n=5):\n",
        "    target = pd.DataFrame(user_input, index=[0])  # Create DataFrame from user input\n",
        "    target['category_encoded'] = encoder.transform([user_input['category']])[0]  # Encode user input category\n",
        "    target_data = target[['category_encoded', 'risk_level', 'returns_1yr', 'returns_3yr', 'returns_5yr']]  # Include relevant columns\n",
        "    data_features = data[['category_encoded', 'risk_level', 'returns_1yr', 'returns_3yr', 'returns_5yr']]\n",
        "    similarity_scores = calculate_similarity(target_data, data_features)\n",
        "    sim_scores_df = pd.DataFrame(similarity_scores.reshape(-1, 1), columns=['similarity'], index=data.index)\n",
        "    recommended_schemes = pd.concat([data, sim_scores_df], axis=1)\n",
        "    recommended_schemes = recommended_schemes.sort_values(by='similarity', ascending=False).head(top_n)\n",
        "    return recommended_schemes[['scheme_name', 'similarity']]\n",
        "\n",
        "# Initialize user input dictionary\n",
        "user_input = {\n",
        "    'category': data['category'].unique()[0],  # Initialize with the first category option\n",
        "    'risk_level': None,\n",
        "    'returns_1yr': None,\n",
        "    'returns_3yr': None,\n",
        "    'returns_5yr': None\n",
        "}\n",
        "\n",
        "\n",
        "# Function to handle dropdown change event\n",
        "def on_category_change(change):\n",
        "    user_input['category'] = change.new\n",
        "\n",
        "# Function to handle textbox change event\n",
        "def on_textbox_change(change):\n",
        "    user_input[change.owner.description.replace(':', '')] = change.new\n",
        "\n",
        "# Function to handle search button click event\n",
        "def on_search_button_click(button):\n",
        "    recommendations = recommend_similar_schemes(user_input, data)\n",
        "    print(\"Top 5 Recommended Schemes:\")\n",
        "    print(recommendations)\n",
        "\n",
        "# Dropdown widget for selecting the category\n",
        "category_dropdown = widgets.Dropdown(\n",
        "    options=data['category'].unique(),\n",
        "    description='Select Category:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Textbox widget for entering risk level\n",
        "risk_level_textbox = widgets.BoundedIntText(\n",
        "    value=3,\n",
        "    min=1,\n",
        "    max=5,\n",
        "    step=1,\n",
        "    description='Risk Level:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Textbox widgets for entering returns for different time periods\n",
        "returns_1yr_textbox = widgets.FloatText(\n",
        "    value=0.0,\n",
        "    description='Returns 1yr:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "returns_3yr_textbox = widgets.FloatText(\n",
        "    value=0.0,\n",
        "    description='Returns 3yr:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "returns_5yr_textbox = widgets.FloatText(\n",
        "    value=0.0,\n",
        "    description='Returns 5yr:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Search button\n",
        "search_button = widgets.Button(description=\"Search\")\n",
        "search_button.on_click(on_search_button_click)\n",
        "\n",
        "# Registering event handlers\n",
        "category_dropdown.observe(on_category_change, names='value')\n",
        "risk_level_textbox.observe(on_textbox_change, names='value')\n",
        "returns_1yr_textbox.observe(on_textbox_change, names='value')\n",
        "returns_3yr_textbox.observe(on_textbox_change, names='value')\n",
        "returns_5yr_textbox.observe(on_textbox_change, names='value')\n",
        "\n",
        "# Displaying the widgets\n",
        "display(category_dropdown)\n",
        "display(risk_level_textbox)\n",
        "display(returns_1yr_textbox)\n",
        "display(returns_3yr_textbox)\n",
        "display(returns_5yr_textbox)\n",
        "display(search_button)\n"
      ],
      "metadata": {
        "id": "kvQyv_q35hZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation System\n"
      ],
      "metadata": {
        "id": "jzUDFpY9l5x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming your dataset is stored in a DataFrame named 'data'\n",
        "# Adjust the column names accordingly\n",
        "\n",
        "# Extract unique values for each column\n",
        "amc_names = data['amc_name'].unique()\n",
        "categories = data['category'].unique()\n",
        "subcategories = data['sub_category'].unique()\n",
        "\n",
        "# Create a dictionary to map categories to their corresponding subcategories\n",
        "subcategory_mapping = {category: data[data['category'] == category]['sub_category'].unique() for category in categories}\n",
        "\n",
        "# Function to filter subcategory options for the \"Hybrid\" category\n",
        "def filter_subcategories(category):\n",
        "    if category == 'Hybrid':\n",
        "        return data[data['category'] == 'Hybrid']['sub_category'].unique()\n",
        "    else:\n",
        "        return subcategory_mapping[category]\n",
        "\n",
        "def enter_investment_details(amc_name, category, subcategory, tenure, amount_invested):\n",
        "    print(\"\\nInvestment Details:\")\n",
        "    print(\"AMC Name:\", amc_name)\n",
        "    print(\"Category:\", category)\n",
        "    print(\"Subcategory:\", subcategory)\n",
        "    print(\"Tenure:\", tenure)\n",
        "    print(\"Amount Invested:\", amount_invested)\n",
        "\n",
        "# Dropdown menus for AMC Name, Category, Subcategory, and Tenure\n",
        "amc_name_dropdown = widgets.Dropdown(options=amc_names, description=\"AMC Name:\")\n",
        "category_dropdown = widgets.Dropdown(options=categories, description=\"Category:\")\n",
        "subcategory_dropdown = widgets.Dropdown(options=subcategories, description=\"Subcategory:\")\n",
        "tenure_dropdown = widgets.Dropdown(options=[\"1-3 yr\", \"3-5 yr\", \"around 5\"], description=\"Tenure:\")\n",
        "\n",
        "# Numeric input for Amount Invested\n",
        "amount_invested_input = widgets.BoundedFloatText(value=0, min=0, max=1000000, step=0.01, description=\"Amount Invested:\")\n",
        "\n",
        "# Display widgets\n",
        "display(amc_name_dropdown, category_dropdown, subcategory_dropdown, tenure_dropdown, amount_invested_input)\n",
        "\n",
        "# Function to update subcategory options based on selected category\n",
        "def update_subcategories(change):\n",
        "    selected_category = change['new']\n",
        "    subcategory_dropdown.options = filter_subcategories(selected_category)\n",
        "\n",
        "# Observe changes in the category dropdown and call the update_subcategories function\n",
        "category_dropdown.observe(update_subcategories, names='value')\n",
        "\n",
        "# Button to submit input\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "display(submit_button)\n",
        "\n",
        "def handle_submit_button_clicked(button):\n",
        "    amc_name = amc_name_dropdown.value\n",
        "    category = category_dropdown.value\n",
        "    subcategory = subcategory_dropdown.value\n",
        "    tenure = tenure_dropdown.value\n",
        "    amount_invested = amount_invested_input.value\n",
        "\n",
        "    enter_investment_details(amc_name, category, subcategory, tenure, amount_invested)\n",
        "\n",
        "submit_button.on_click(handle_submit_button_clicked)\n"
      ],
      "metadata": {
        "id": "5ZIkezsT0VDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0YvOEXTQl3hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the recommend_scheme_names function\n",
        "def recommend_scheme_names(amc_name, category, subcategory, tenure, amount_invested):\n",
        "    # Filter the dataset based on selected input values\n",
        "    filtered_data = data[\n",
        "        (data['amc_name'] == amc_name) &\n",
        "        (data['category'] == category) &\n",
        "        (data['sub_category'] == subcategory)\n",
        "       ]\n",
        "\n",
        "    # Check if any schemes are found matching the criteria\n",
        "    if not filtered_data.empty:\n",
        "        # Define columns for sorting\n",
        "        arrange_columns1 = ['sortino', 'alpha', 'sharpe', 'rating']\n",
        "        arrange_columns2 = ['beta', 'sd']\n",
        "\n",
        "        # Sort the filtered data based on multiple sets of columns\n",
        "        arranged_data1 = filtered_data.sort_values(by=arrange_columns1, ascending=False)\n",
        "        arranged_data2 = filtered_data.sort_values(by=arrange_columns2, ascending=True)\n",
        "\n",
        "        # Combine the recommendations from both sorted dataframes\n",
        "        recommended_schemes = (arranged_data1['scheme_name'].head(5) + arranged_data2['scheme_name'].head(5)).tolist()\n",
        "\n",
        "        return recommended_schemes\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Example usage (assuming data and other dependencies are defined/imported)\n",
        "amc_name = amc_name_dropdown.value\n",
        "category = category_dropdown.value\n",
        "subcategory = subcategory_dropdown.value\n",
        "tenure = tenure_dropdown.value\n",
        "amount_invested = amount_invested_input.value\n",
        "\n",
        "# Get recommendations\n",
        "import math\n",
        "recommendations = recommend_scheme_names(amc_name, category, subcategory, tenure, amount_invested)\n",
        "recommendations = [scheme for scheme in recommendations if not (isinstance(scheme, float) and math.isnan(scheme))]\n",
        "# Print the recommendations\n",
        "if recommendations:\n",
        "    print(\"Top 5 Recommended Scheme Names:\")\n",
        "    for i, scheme_name in enumerate(recommendations, start=1):\n",
        "\n",
        "        print(f\"{i}. {scheme_name}\")\n",
        "else:\n",
        "    print(\"No schemes found matching the criteria.\")\n"
      ],
      "metadata": {
        "id": "bydrcBxBZwMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKSeZ06LilBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Portfolio Diversification &            Calculator"
      ],
      "metadata": {
        "id": "4dtqRZ5DimBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the mutual fund data\n",
        "mutual_funds_data = pd.read_csv('/content/MF_India_AI.csv')\n",
        "\n",
        "# Function to calculate potential returns\n",
        "def calculate_returns(investment_amount, duration_years, selected_scheme):\n",
        "    # Filter data for the selected scheme\n",
        "    scheme_data = mutual_funds_data[mutual_funds_data['scheme_name'] == selected_scheme]\n",
        "\n",
        "    # Get returns for different time periods\n",
        "    returns_1yr = scheme_data['returns_1yr'].iloc[0] / 100\n",
        "    returns_3yr = scheme_data['returns_3yr'].iloc[0] / 100\n",
        "    returns_5yr = scheme_data['returns_5yr'].iloc[0] / 100\n",
        "\n",
        "    # Calculate potential returns\n",
        "    returns_1yr_amount = investment_amount * (1 + returns_1yr) ** duration_years\n",
        "    returns_3yr_amount = investment_amount * (1 + returns_3yr) ** duration_years\n",
        "    returns_5yr_amount = investment_amount * (1 + returns_5yr) ** duration_years\n",
        "\n",
        "    return returns_1yr_amount, returns_3yr_amount, returns_5yr_amount\n",
        "\n",
        "# User input\n",
        "investment_amount = float(input(\"Enter investment amount (INR): \"))\n",
        "duration_years = int(input(\"Enter investment duration (years): \"))\n",
        "selected_scheme = input(\"Enter selected scheme: \")\n",
        "\n",
        "# Calculate potential returns\n",
        "returns_1yr_amount, returns_3yr_amount, returns_5yr_amount = calculate_returns(investment_amount, duration_years, selected_scheme)\n",
        "\n",
        "# Display potential returns\n",
        "print(\"\\nPotential Returns after\", duration_years, \"years for\", selected_scheme)\n",
        "print(\"Returns after 1 year:\", round(returns_1yr_amount, 2), \"INR\")\n",
        "print(\"Returns after 3 years:\", round(returns_3yr_amount, 2), \"INR\")\n",
        "print(\"Returns after 5 years:\", round(returns_5yr_amount, 2), \"INR\")"
      ],
      "metadata": {
        "id": "z3co6zmailEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}